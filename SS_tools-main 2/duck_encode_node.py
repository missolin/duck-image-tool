import hashlib
import io
import os
import os
import struct
from typing import Tuple, List, Any
try:
    from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_audioclips
except ImportError:
    try:
        from moviepy import ImageSequenceClip, AudioFileClip, concatenate_audioclips
    except ImportError:
        print("âŒ MoviePy import failed. Please install moviepy: pip install moviepy")
        ImageSequenceClip = None
        AudioFileClip = None
        concatenate_audioclips = None
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import torch
import tempfile
try:
    import folder_paths  # type: ignore
except Exception:  # pragma: no cover
    folder_paths = None

try:
    from .duck_payload_exporter import export_duck_payload, _bytes_to_binary_image, _required_canvas_size, _build_file_header
except ImportError:
    from duck_payload_exporter import export_duck_payload, _bytes_to_binary_image, _required_canvas_size, _build_file_header


# åˆ†ç±»åç§°è¦æ±‚
CATEGORY = "SSTool"
LSB_BITS_PER_CHANNEL = 2
DUCK_CHANNELS = 3
WATERMARK_SKIP_W_RATIO = 0.40
WATERMARK_SKIP_H_RATIO = 0.08




def _tensor_to_pil(image: torch.Tensor) -> Image.Image:
    """å°† ComfyUI çš„ IMAGE Tensor è½¬ä¸º PIL.Imageã€‚"""
    if image.dim() == 4:
        image = image[0]
    image = image.detach().cpu().numpy()
    image = np.clip(image * 255.0, 0, 255).astype(np.uint8)
    return Image.fromarray(image)


def _pil_to_tensor(image: Image.Image) -> torch.Tensor:
    """å°† PIL.Image è½¬ä¸º ComfyUI éœ€è¦çš„ IMAGE Tensorã€‚"""
    arr = np.array(image).astype(np.float32) / 255.0
    return torch.from_numpy(arr)[None, ...]




# ===================== æ ¸å¿ƒï¼šå¤ç”¨VideoHelperSuiteçš„éŸ³é¢‘è§£æé€»è¾‘ =====================
def export_lazy_audio_to_file(audio_obj) -> str:

    path_attr = getattr(audio_obj, "file", None)
    if isinstance(path_attr, str) and os.path.exists(path_attr):
        return path_attr


    temp_audio_path = tempfile.mkstemp(suffix=".wav")
    # mkstempè¿”å›(fd, path)ï¼Œæˆ‘ä»¬éœ€è¦pathï¼Œå¹¶å…³é—­fd
    os.close(temp_audio_path[0])
    temp_audio_path = temp_audio_path[1]

    try:

        if isinstance(audio_obj, torch.Tensor):
            import soundfile as sf
            audio_np = audio_obj.detach().cpu().numpy()
            if audio_np.ndim == 1:
                audio_np = audio_np[:, None]
            if audio_np.ndim == 2 and audio_np.shape[0] < audio_np.shape[1]:
                audio_np = audio_np.T
            sf.write(temp_audio_path, audio_np, samplerate=44100)
            print(f"âœ… å¯¼å‡ºéŸ³é¢‘å¼ é‡ä¸ºWAVï¼š{temp_audio_path}")
            print(f"âœ… Export audio tensor to WAV: {temp_audio_path}")
            return temp_audio_path

        elif isinstance(audio_obj, np.ndarray):
            import soundfile as sf
            arr = audio_obj
            if arr.ndim == 1:
                arr = arr[:, None]
            if arr.ndim == 2 and arr.shape[0] < arr.shape[1]:
                arr = arr.T
            sf.write(temp_audio_path, arr, samplerate=44100)
            print(f"âœ… å¯¼å‡ºnumpyéŸ³é¢‘ä¸ºWAVï¼š{temp_audio_path}")
            print(f"âœ… Export numpy audio to WAV: {temp_audio_path}")
            return temp_audio_path

        elif isinstance(audio_obj, dict):
            import soundfile as sf
            # ä¼˜å…ˆæ£€æŸ¥ waveform (ComfyUI æ ‡å‡†æ ¼å¼)
            data = audio_obj.get("waveform")
            if data is None:
                data = audio_obj.get("samples") or audio_obj.get("audio")
            
            sr = audio_obj.get("sample_rate") or audio_obj.get("samplerate") or 44100
            
            if data is not None:
                # å¤„ç† Tensor è½¬ numpy
                if hasattr(data, "cpu"):
                    arr = data.detach().cpu().numpy()
                else:
                    arr = np.array(data)
                
                # å¤„ç†ç»´åº¦ (Batch, Channels, Samples)
                if arr.ndim == 3:
                    arr = arr.squeeze(0)  # ç§»é™¤ batch ç»´åº¦ (1, C, N) -> (C, N)
                
                if arr.ndim == 1:
                    arr = arr[:, None]
                # (Channels, Samples) -> (Samples, Channels) for soundfile
                if arr.ndim == 2 and arr.shape[0] < arr.shape[1]:
                    arr = arr.T
                
                sf.write(temp_audio_path, arr, samplerate=int(sr))
                print(f"âœ… å¯¼å‡ºdictéŸ³é¢‘ä¸ºWAVï¼š{temp_audio_path}")
                print(f"âœ… Export dict audio to WAV: {temp_audio_path}")
                return temp_audio_path

        elif isinstance(audio_obj, (tuple, list)) and len(audio_obj) >= 1:
            import soundfile as sf
            arr = np.array(audio_obj[0])
            sr = audio_obj[1] if len(audio_obj) > 1 else 44100
            if arr.ndim == 1:
                arr = arr[:, None]
            if arr.ndim == 2 and arr.shape[0] < arr.shape[1]:
                arr = arr.T
            sf.write(temp_audio_path, arr, samplerate=int(sr))
            print(f"âœ… å¯¼å‡ºtuple/listéŸ³é¢‘ä¸ºWAVï¼š{temp_audio_path}")
            print(f"âœ… Export tuple/list audio to WAV: {temp_audio_path}")
            return temp_audio_path

        elif isinstance(audio_obj, str):
            if os.path.exists(audio_obj):
                import shutil
                shutil.copy2(audio_obj, temp_audio_path)
                print(f"âœ… å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶è·¯å¾„ï¼š{temp_audio_path}")
                print(f"âœ… Copy audio file to temp path: {temp_audio_path}")
                return temp_audio_path
            raise FileNotFoundError(f"éŸ³é¢‘è·¯å¾„ä¸å­˜åœ¨ï¼š{audio_obj}")

        raise TypeError(f"ä¸æ”¯æŒçš„éŸ³é¢‘ç±»å‹ï¼š{type(audio_obj)}")

    except Exception as e:
        print(f"âŒ Export audio failed: {str(e)}")
        print(f"âŒ å¯¼å‡ºéŸ³é¢‘å¤±è´¥ï¼š{str(e)}")
        if os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)
        return None

class DuckHideNode:
    """ç”Ÿæˆé¸­å­å›¾å¹¶å°†çœŸå®å›¾ç‰‡/è§†é¢‘æ•°æ®éšè—å…¶ä¸­ï¼Œå¯é€‰å¯†ç ä¿æŠ¤ã€‚"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "password": ("STRING", {"default": "", "multiline": False}),
                "title": ("STRING", {"default": "", "multiline": False}),
                "fps": ("INT", {"default": 16, "min": 1, "max": 60, "step": 1, "tooltip": "fpså¿…é¡»ä¸ºæ•´æ•°ï¼Œintç±»å‹"}),
                "compress": ([2, 6, 8], {"default": 2, "tooltip": "é€‰æ‹©å‹ç¼©æ–¹å¼ï¼Œ8ä¸ºæœ€å°ä½“ç§¯"}),
                "combine_video": ("BOOLEAN", {"default": True, "tooltip": "å¦‚æœä¸ºfalseåˆ™ä¸ä¼šåˆæˆè§†é¢‘ï¼Œå¼ºåˆ¶è¾“å‡ºç»„å›¾"}),
                
            },
            "optional": {
                "images": ("IMAGE",),
                "audio": ("AUDIO",),
                "text_input": ("STRING", {"forceInput": True}),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("duck_image",)
    FUNCTION = "hide"
    CATEGORY = CATEGORY

    def _convert_comfy_image_to_cv2(self, comfy_image):
        img = np.rint(comfy_image.detach().cpu().numpy() * 255.0).astype(np.uint8)
        if img.ndim == 4:
            img = img.squeeze(0)
        if img.shape[-1] == 4:
            img = img[..., :3]
        return img

    def _parse_comfy_audio(self, audio: Any) -> str:
        """
        ç»Ÿä¸€è§£æéŸ³é¢‘ï¼šå¤ç”¨ä¿å­˜éŸ³é¢‘èŠ‚ç‚¹çš„exporté€»è¾‘
        """
        if audio is None or audio == "":
            return None
        
        # æ ¸å¿ƒï¼šè°ƒç”¨å¯¼å‡ºå‡½æ•°ï¼Œå°†ä»»æ„éŸ³é¢‘å¯¹è±¡è½¬ä¸ºä¸´æ—¶æ–‡ä»¶è·¯å¾„
        audio_path = export_lazy_audio_to_file(audio)
        return audio_path

    def _images_to_video(self, images: List[Image.Image], fps: float, audio: Any) -> np.ndarray:
        # """å°†å¤šå¼ å›¾ç‰‡åˆæˆè§†é¢‘"""
        frame_list = []
        for img in images:
            rgb_img = self._convert_comfy_image_to_cv2(img)
            frame_list.append(rgb_img)

        clip = ImageSequenceClip(frame_list, fps=fps)
        audio_clip = None
        
        # 1. å°è¯•åŠ è½½éŸ³é¢‘
        if audio is not None and audio != "":
            try:
                print("æ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥ï¼Œå°è¯•åµŒå…¥è§†é¢‘ä¸­")
                print("Audio detected, attempting to embed into video")
                audio_path = self._parse_comfy_audio(audio)
                print("audio_path:", audio_path)
                
                if audio_path is not None:
                    try:
                        loaded_audio = AudioFileClip(audio_path)
                        # æ£€æŸ¥éŸ³é¢‘æœ‰æ•ˆæ€§
                        if loaded_audio.duration <= 0.05:
                            print(f"âš ï¸ Audio duration too short ({loaded_audio.duration}s), ignoring audio.")
                            loaded_audio.close()
                            audio_clip = None
                        else:
                            audio_clip = loaded_audio
                    except Exception as e:
                         print(f"âš ï¸ Failed to load AudioFileClip: {e}, ignoring audio.")
                         audio_clip = None

                    if audio_clip:
                        # éŸ³é¢‘å¤„ç†é€»è¾‘ (å¾ªç¯/æˆªæ–­)
                        if audio_clip.duration > clip.duration:
                            if hasattr(audio_clip, 'subclip'):
                                audio_clip = audio_clip.subclip(0, clip.duration)
                            else:
                                audio_clip = audio_clip.subclipped(0, clip.duration)
                        else:
                            repeats = int(clip.duration // audio_clip.duration)
                            remainder = clip.duration - repeats * audio_clip.duration
                            parts = []
                            if repeats <= 0:
                                if hasattr(audio_clip, 'subclip'):
                                     parts.append(audio_clip.subclip(0, min(audio_clip.duration, clip.duration)))
                                else:
                                     parts.append(audio_clip.subclipped(0, min(audio_clip.duration, clip.duration)))
                            else:
                                for _ in range(repeats):
                                    parts.append(audio_clip)
                                if remainder > 0:
                                    if hasattr(audio_clip, 'subclip'):
                                        parts.append(audio_clip.subclip(0, remainder))
                                    else:
                                        parts.append(audio_clip.subclipped(0, remainder))
                            audio_clip = concatenate_audioclips(parts)
                        
                        # è®¾ç½®éŸ³é¢‘åˆ°è§†é¢‘å‰ªè¾‘
                        if hasattr(clip, 'set_audio'):
                             clip = clip.set_audio(audio_clip)
                        else:
                             clip = clip.with_audio(audio_clip)
            except Exception as e:
                print(f"âš ï¸ Audio processing error: {e}, continue without audio.")
                if audio_clip:
                    audio_clip.close()
                audio_clip = None
                # ç§»é™¤å·²è®¾ç½®çš„éŸ³é¢‘
                if hasattr(clip, 'set_audio'):
                     clip = clip.set_audio(None)
                else:
                     clip = clip.with_audio(None)

        # 2. å°è¯•å†™å…¥è§†é¢‘æ–‡ä»¶ (å¸¦é‡è¯•æœºåˆ¶)
        temp_video_path = None
        try:
            def write_video(use_audio=True):
                # å¿…é¡» delete=False å¦åˆ™ win ä¸‹æ— æ³•è¯»å–
                with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as tf:
                    t_path = tf.name
                
                # å¦‚æœä¸ä½¿ç”¨éŸ³é¢‘ï¼Œå¼ºåˆ¶ç§»é™¤
                current_clip = clip
                if not use_audio:
                    if hasattr(current_clip, 'set_audio'):
                        current_clip = current_clip.set_audio(None)
                    else:
                        current_clip = current_clip.with_audio(None)

                current_clip.write_videofile(
                    t_path,
                    codec="libx264",
                    audio_codec="aac" if use_audio and current_clip.audio else None,
                    fps=fps,
                    ffmpeg_params=[
                        "-pix_fmt","yuv420p",
                        "-crf","16",
                        "-preset","medium",
                        "-profile:v","high",
                        "-movflags","+faststart"
                    ]
                )
                return t_path

            try:
                # ç¬¬ä¸€æ¬¡å°è¯•ï¼šå¦‚æœ audio_clip å­˜åœ¨ï¼Œåˆ™å°è¯•å¸¦éŸ³é¢‘å†™å…¥
                temp_video_path = write_video(use_audio=(audio_clip is not None))
            except (IndexError, OSError, Exception) as e:
                if audio_clip is not None:
                    print(f"âŒ Video encoding with audio failed: {e}")
                    print("ğŸ”„ Retrying without audio...")
                    # æ¸…ç†ç¬¬ä¸€æ¬¡å¤±è´¥çš„ä¸´æ—¶æ–‡ä»¶ (å¦‚æœæœ‰)
                    if temp_video_path and os.path.exists(temp_video_path):
                        try:
                            os.unlink(temp_video_path)
                        except:
                            pass
                    # é‡è¯•ä¸å¸¦éŸ³é¢‘
                    temp_video_path = write_video(use_audio=False)
                else:
                    # å¦‚æœæœ¬æ¥å°±æ²¡éŸ³é¢‘è¿˜å¤±è´¥äº†ï¼Œé‚£å°±çœŸå¤±è´¥äº†
                    raise e

            # è¯»å–æœ€ç»ˆæˆåŠŸçš„ä¸´æ—¶æ–‡ä»¶
            with open(temp_video_path, "rb") as f:
                video_bytes = f.read()

        finally:
            # å¼ºåˆ¶é‡Šæ”¾èµ„æº
            clip.close()
            if audio_clip:
                audio_clip.close()
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if temp_video_path and os.path.exists(temp_video_path):
                try:
                    os.unlink(temp_video_path)
                except:
                    pass

        return video_bytes

    def hide(self, fps: float, password: str, title: str, compress: int, combine_video: bool, images=None, audio=None, Notes: str = "", text_input: str = ""):
        return self._hide(fps, password, title, compress, combine_video, images, audio, Notes, text_input=text_input)

    def _hide(self, fps: float, password: str, title: str, compress: int, combine_video: bool, images=None, audio=None, Notes: str = "", video_path="", text_input: str = ""):
        # ä¼˜å…ˆå¤„ç†æ–‡æœ¬è¾“å…¥
        if text_input and text_input.strip():
            raw_bytes = text_input.encode("utf-8")
            ext = "txt"
            
            out_path, duck_img = export_duck_payload(
                raw_bytes=raw_bytes,
                password=password,
                ext=ext,
                compress=compress,
                title=title,
                output_dir=(folder_paths.get_output_directory() if folder_paths else os.getcwd()),
                output_name="duck_payload_txt.png",
            )
            duck_tensor = _pil_to_tensor(duck_img)
            return (duck_tensor,)

        # image 
        if images is None and not video_path:
            raise ValueError("Images, video_path or text_input required. éœ€è¦æä¾› images, video_path æˆ– text_input ã€‚")

        if isinstance(images, (torch.Tensor, np.ndarray)):
            # è·å–ç»´åº¦ï¼š3ç»´=å•å¸§ï¼Œ4ç»´=å¤šå¸§åºåˆ—
            dims = len(images.shape)
            if dims == 4:
                # Load Videoè¾“å‡ºçš„4ç»´å¸§åºåˆ— (N, H, W, C)
                frame_count = images.shape[0]
                # æ‹†åˆ†4ç»´å¼ é‡ä¸ºå•å¸§åˆ—è¡¨
                frame_list = [images[i] for i in range(frame_count)]
            elif dims == 3:
                # å•å¼ å›¾ç‰‡ (H, W, C)
                frame_count = 1
                frame_list = [images]
            else:
                raise ValueError(f"Unsupported input dims: {dims} (only 3/4D). ä¸æ”¯æŒçš„è¾“å…¥ç»´åº¦ï¼š{dims}ï¼ˆä»…æ”¯æŒ3/4ç»´ï¼‰")
        elif isinstance(images, list):
            # æ‰‹åŠ¨ä¼ å…¥çš„å›¾ç‰‡åˆ—è¡¨
            frame_count = len(images)
            frame_list = images
        else:
            # æœªçŸ¥ç±»å‹ï¼ŒæŒ‰å•å¸§å¤„ç†
            frame_count = 1
            frame_list = [images]


        if video_path:
            # ç›´æ¥ä½¿ç”¨è§†é¢‘æ–‡ä»¶
            with open(video_path, "rb") as f:
                vid_bytes = f.read()
                # è½¬ä¸ºäºŒè¿›åˆ¶å›¾ç‰‡ï¼Œå†èµ°å›¾ç‰‡é€»è¾‘
                bin_img = _bytes_to_binary_image(vid_bytes, width=512)
                with io.BytesIO() as buf:
                    bin_img.save(buf, format="PNG")
                    raw_bytes = buf.getvalue()
                orig_ext = os.path.splitext(video_path)[1].lower().lstrip('.')
                ext = f"{orig_ext}.binpng"

        elif not combine_video and frame_count > 1:
            print("Output as image list (è¾“å‡ºä¸ºå›¾ç‰‡åˆ—è¡¨)")
            duck_results = []
            
            # é¢„å¤„ç†ï¼šç”Ÿæˆæ‰€æœ‰ raw_bytes å¹¶è®¡ç®—æœ€å¤§æ‰€éœ€å°ºå¯¸ï¼Œç¡®ä¿æ‰€æœ‰è¾“å‡ºå›¾ç‰‡å°ºå¯¸ä¸€è‡´ä¸”æ•°æ®ç»“æ„å®Œæ•´
            raw_bytes_list = []
            max_required_size = 0
            lsb_bits = 8 if compress >= 8 else (6 if compress >= 6 else 2)
            
            for i, frame_tensor in enumerate(frame_list):
                pil = _tensor_to_pil(frame_tensor)
                with io.BytesIO() as buf:
                    pil.save(buf, format="PNG")
                    raw_bytes = buf.getvalue()
                raw_bytes_list.append(raw_bytes)
                
                # è®¡ç®—æ‰€éœ€å°ºå¯¸
                ext = "png"
                file_header = _build_file_header(raw_bytes, password, ext=ext)
                req_size = _required_canvas_size((len(file_header) + 4) * 8, lsb_bits)
                if req_size > max_required_size:
                    max_required_size = req_size
            
            print(f"Unified canvas size for image list: {max_required_size}x{max_required_size}")
            
            # å†…å­˜ä¼˜åŒ–ï¼šé¢„åˆ†é…æœ€ç»ˆ Tensorï¼Œé¿å… torch.cat å¸¦æ¥çš„å†…å­˜å³°å€¼ (List + Tensor åŒå€å ç”¨)
            # å½¢çŠ¶: (frame_count, H, W, C)
            result_tensor = torch.zeros((frame_count, max_required_size, max_required_size, 3), dtype=torch.float32)
            
            for i, raw_bytes in enumerate(raw_bytes_list):
                ext = "png"
                out_name = f"duck_payload_seq_{i:05d}.png" 
                
                out_path, duck_img = export_duck_payload(
                    raw_bytes=raw_bytes,
                    password=password,
                    ext=ext,
                    compress=compress,
                    title=f"{title} ({i+1}/{frame_count})",
                    output_dir=(folder_paths.get_output_directory() if folder_paths else os.getcwd()),
                    output_name=out_name,
                    fixed_size=max_required_size, # å¼ºåˆ¶ä½¿ç”¨ç»Ÿä¸€å°ºå¯¸
                )
                
                # ç›´æ¥å†™å…¥é¢„åˆ†é…çš„ Tensor
                # _pil_to_tensor è¿”å› (1, H, W, C)ï¼Œæˆ‘ä»¬éœ€è¦ [0] å–å‡º (H, W, C)
                result_tensor[i] = _pil_to_tensor(duck_img)[0]
            
            # æ¸…ç† raw_bytes_list ä»¥é‡Šæ”¾å†…å­˜ (è™½ç„¶ Python ä¼šè‡ªåŠ¨å›æ”¶ï¼Œä½†æ˜¾å¼æ¸…ç†æ˜¯ä¸ªå¥½ä¹ æƒ¯)
            del raw_bytes_list

            return (result_tensor,)

        elif frame_count > 1:
            print("æ£€æµ‹åˆ°è§†é¢‘è¾“å…¥ï¼Œåˆæˆè§†é¢‘ä¸­")
            print("Detected video input, composing video")
            print("å›¾ç‰‡å¼ æ•°ï¼š",frame_count)
            print("Number of images:", frame_count)
            #åˆæˆè§†é¢‘
            vid_bytes = self._images_to_video(frame_list, fps,audio)

            # è½¬ä¸ºäºŒè¿›åˆ¶å›¾ç‰‡ï¼Œå†èµ°å›¾ç‰‡é€»è¾‘
            bin_img = _bytes_to_binary_image(vid_bytes, width=512)
            with io.BytesIO() as buf:
                bin_img.save(buf, format="PNG")
                raw_bytes = buf.getvalue()
            orig_ext = "mp4"
            ext = f"{orig_ext}.binpng"
        else:
            pil = _tensor_to_pil(frame_list[0])
            with io.BytesIO() as buf:
                pil.save(buf, format="PNG")
                raw_bytes = buf.getvalue()
            ext = "png"

        out_path, duck_img = export_duck_payload(
            raw_bytes=raw_bytes,
            password=password,
            ext=ext,
            compress=compress,
            title=title,
            output_dir=(folder_paths.get_output_directory() if folder_paths else os.getcwd()),
            output_name="duck_payload.png",
        )

        duck_tensor = _pil_to_tensor(duck_img)
        return (duck_tensor,)


NODE_CLASS_MAPPINGS = {"DuckHideNode": DuckHideNode}
NODE_DISPLAY_NAME_MAPPINGS = {"DuckHideNode": "é¸­é¸­å›¾ SuperSecureMediaProtectionåª’ä½“å†…å®¹ä¿æŠ¤ ç¼–ç V1.2"}

